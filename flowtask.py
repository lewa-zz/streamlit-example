#!/usr/bin/python3
# -*- coding:utf-8 -*-
# ==========================================
#       Author: RicoChen
#        ğŸ“§Mail: 55059@qq.com
#         âŒšTime: 2023/4/4
#           Version:
#             Description: ä»ç½‘ä¸Šä¸­ä»‹è¶…å¸‚æ‹¿æ•°æ®
# ==========================================
from playwright.sync_api import Playwright, sync_playwright, expect
import pandas as pd
import re,time
import sqlite3
from datetime import datetime 
from prefect import task, flow, get_run_logger

data = {'åºå·':[],'href':[],'é¡¹ç›®åç§°':[],'é¡¹ç›®ä¸šä¸»':[],'æœåŠ¡ç±»å‹':[],'ä¸­é€‰æœºæ„':[], #ç¬¬ä¸€é¡µé€‰å–
    'é‡‡è´­é¡¹ç›®ç¼–ç ':[],'é‡‘é¢è¯´æ˜':[],'æœåŠ¡é‡‘é¢':[], 'to_page3':[],         #ç¬¬äºŒé¡µé€‰å–
    'é¡¹ç›®è§„æ¨¡':[],'æœåŠ¡å†…å®¹':[],'æ‹ŸæœåŠ¡é‡‘é¢':[],'æ—¶é—´':[]}  #data= dict()        #ç¬¬ä¸‰é¡µé€‰å–ï¼Œæ—¶é—´æ˜¯ç¬¬ä¸€é¡µçš„
base_url:str = r"https://ygp.gdzwfw.gov.cn"


@task(name="æ‹‰å–ä»»åŠ¡Task-{page}", 
      retries=30, retry_delay_seconds=30,description="Get the Data by request")
def get_data(page: int):
    import requests
    import json
    from urllib import parse

    # å®šä¹‰è¯·æ±‚header
    HEADERS = {'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8', 'Key': '332213fa4a9d4288b5668ddd9'}
    # å®šä¹‰è¯·æ±‚åœ°å€
    url = "https://ygp.gdzwfw.gov.cn/zjfwcs/gd-zjcs-pub/bidResultNotice/rest"
    # é€šè¿‡å­—å…¸æ–¹å¼å®šä¹‰è¯·æ±‚body
    FormData = {"listVo.divisionCode": '441900', 
                "listVo.bidResultDateBegin": '2022-01-01', 
                "listVo.bidResultDateEnd":"2022-5-20",
                "pageNumber": page,
                "sourtType":""}
    # å­—å…¸è½¬æ¢k1=v1 & k2=v2 æ¨¡å¼
    data = parse.urlencode(FormData)
    # è¯·æ±‚æ–¹å¼
    content = requests.post(url=url, headers=HEADERS, data=data)
    print("è¿”å›ç :%s"%content.status_code)
    if content.status_code != 200:
        raise Exception('ç¬¬%dæ‹‰å–å¼‚å¸¸ï¼'%page)
    #content = json.loads(content)
    content = content.text
    #print(content)
    with open(r'./html/adata%d.html'%page, 'w') as f:
        f.write(content)
    return content

@flow(flow_run_name="{name}-on-{page}")
def my_flow(name: str, page: int ):
    logger = get_run_logger()
    logger.info('%s ç¬¬%dé¡µå¯åŠ¨'%(name,page))
    get_data(page)

@task(name="é¡µé¢åŠ è½½", 
      retries=30, retry_delay_seconds=30,description="Get the Data by request")
def load_page(page, href: str):
    #href = 'https://ygp.gdzwfw.gov.cn/zjfwcs/gd-zjcs-pub/bidResultNotice/view/4419001257480170562212270347'
    r = page.goto(href)
    if r.status != 200:
        raise Exception("é¡µé¢åŠ è½½å¤±è´¥ï¼Œé‡è¯•ä¸­ï¼")
    return page

@flow(flow_run_name="ä»EXCELè¯»å‡ºæ‹‰é¡µé¢")
def read_excel(file_path):
    '''
    pandasè¯»excel
    read_excelçš„åŸå‹ï¼šread_excel(io, sheet_name=0, header=0, names=None, index_col=None, usecols=None)
    '''
    #file_path = r'./æ€»è¾“å‡º.xlsx'
    # sheet_nameä¸æŒ‡å®šæ—¶é»˜è®¤è¿”å›å…¨è¡¨æ•°æ®
    df = pd.read_excel(file_path, sheet_name="Sheet1", header=0)
    # æ‰“å°åˆ—æ ‡é¢˜,å³è¡¨å¤´
    print(df.columns)
    total_rows = len(df)
    print('æ€»æ•°:{0} è¡Œæ•°{1}', format(df.index.size), str(total_rows))
    data2 = df.to_dict(orient='list')
    j = 0
    for row_index, row in df.iterrows():
        di:dict = popup_page3(row['to_page3'], row_index)
        # row['åºå·'] =  row_index
        # row["é¡¹ç›®è§„æ¨¡"] = di["amo"]
        # row["æœåŠ¡å†…å®¹"] = di["content"]+'wwwwwww'
        # row['æ‹ŸæœåŠ¡é‡‘é¢'] = di['servie_amo']
        data2['åºå·'][row_index] =  row_index
        data2["é¡¹ç›®è§„æ¨¡"][row_index] = di["amo"]
        data2["æœåŠ¡å†…å®¹"][row_index] = di["content"]
        data2['æ‹ŸæœåŠ¡é‡‘é¢'][row_index] = di['servie_amo']
        j += 1
        if j == 20: #æ¯20æ¡å­˜ä¸€æ¬¡ç›˜å§
            df = pd.DataFrame(data2)
            df.to_excel('è¾“å‡º.xlsx')
            j=0
            #break
    df = pd.DataFrame(data2)
    df.to_excel('è¾“å‡º.xlsx')  

@task(name="{num}ä»»åŠ¡åŠ è½½", 
      retries=10, retry_delay_seconds=1,description="Get the Data by request")
def popup_page3(href: str,num):
    with sync_playwright() as playwright:
        browser = playwright.chromium.launch(headless=True)    
        context = browser.new_context()
        new_page = context.new_page()
        _do = True
        while _do:
            _do = False
            #load_page(new_page,href)
            r = new_page.goto(href)
            if r.status != 200:
                new_page.close()
                time.sleep(1)
                new_page = context.new_page()
                _do =True
        try:
            amo = new_page.locator('div > ul > li:has-text("é¡¹ç›®è§„æ¨¡")').locator("div").text_content()
        #amo = new_page2.get_by_role("li").filter(has_text="é¡¹ç›®è§„æ¨¡")
            _kk = re.compile(r'\d+\.?\d+') #æ­£åˆ™ä¸­å°æ•°ç‚¹åŠ \è½¬ä¹‰,ä¸ç„¶.å°±è¯†åˆ«ä»»ä¸€å­—ç¬¦
            kk = re.findall(_kk,amo.replace(",",""))
            amo = float(kk[0]) if len(kk) != 0 else 0
        except:
            amo = 0
        #data["é‡‘é¢"].append(amo)
        #scale = new_page.locator('div > ul > li:has-text("é¡¹ç›®è§„æ¨¡")').locator("div").text_content()
        try:
            content = new_page.locator('li:has-text("æœåŠ¡å†…å®¹")').locator("div").text_content()
        except:
            content=""

        try:
            servie_amo =new_page.locator('div > ul > li:has-text("æœåŠ¡é‡‘é¢")').locator("div").text_content()
        except:
            servie_amo = 0
        #servie_amo = new_page.locator('li:has-text("æœåŠ¡é‡‘é¢")').locator("div").text_content()
        #data["æœåŠ¡å†…å®¹"].append(content)
        new_page.close()
    # time.sleep(2)
    return locals()

#ä¸­é€‰å…¬å‘Šé¡µé¢æ•°
#@task(name="æ‰“å¼€ç¬¬äºŒé¡µTask",retries=3, retry_delay_seconds=10,description="Get the Data by request")
def popup_page2(context,href):
    new_page = context.new_page()
    _do = True
    while _do:
        _do = False
        #load_page(new_page,href)
        r = new_page.goto(href)
        if r.status != 200:
            new_page.close()
            time.sleep(3)
            new_page = context.new_page()
            _do =True

    to_page3 = new_page.locator('li:has-text("é‡‡è´­é¡¹ç›®åç§°")').locator("a").get_attribute("href") # Opens a new tab
    purchase_nu = new_page.locator('div > ul > li:has-text("é‡‡è´­é¡¹ç›®ç¼–ç ")').locator("div").text_content()
    amo_memo =  new_page.locator('div > ul > li:has-text("é‡‘é¢è¯´æ˜")').locator("div").text_content()
    try:
        servie_amo =new_page.locator('div > ul > li:has-text("æœåŠ¡é‡‘é¢")').locator("div").text_content()
    except:
        servie_amo = 0
    #selected_amo = new_page.locator('div > ul > li:has-text("ä¸­é€‰é‡‘é¢")').locator("div").text_content()
    new_page.close()
    # time.sleep(2)
    return locals()

def run(playwright: Playwright,htmlfile: str) -> None:
    global data
    browser = playwright.chromium.launch(headless=False)
    page = browser.new_page()
    #browser,context,page = open_browser()
    page.goto(htmlfile)
    #page.wait_for_timeout(1000)
    #å®šä½è¡¨æ ¼çš„è¡Œ,ç„¶åéå†
    tr = page.locator('//*[@id="resultPannel"]/table/tbody/tr') #[1]/td[1]'.locator("a")
    #print(li.text_content())  
    i = 0 
    for row in tr.all():
        data['åºå·'].append(i)
        #å®šä½æ¯è¡Œä¸‹é¢çš„åˆ—TD
        td = row.locator("td").all()
        # tdo = expect(row.locator("td")).to_have_count(5)æœŸå¾…æœ‰5åˆ—
        alink = td[0].get_by_role("link") #æˆ–ahref = row.locator("a")
        ahref = base_url+str(alink.get_attribute("href"))
        data["href"].append(ahref)
        data["é¡¹ç›®åç§°"].append(alink.text_content())
        data["é¡¹ç›®ä¸šä¸»"].append(td[1].inner_text())
        data["æœåŠ¡ç±»å‹"].append(td[2].inner_text())
        data["ä¸­é€‰æœºæ„"].append(td[3].inner_text())
        data["æ—¶é—´"].append(td[4].inner_text())
        #print("url is %s ,content is :%s"%(td[0].get_attribute("href"),td[0].text_content))
        i += 1
        #å¤„ç†ç¬¬äºŒé¡µ
        di:dict = popup_page2(browser.new_context(),ahref)
        data["é‡‡è´­é¡¹ç›®ç¼–ç "].append(di["purchase_nu"])
        data["é‡‘é¢è¯´æ˜"].append(di["amo_memo"])
        data["æœåŠ¡é‡‘é¢"].append(di["servie_amo"])
        #data["ä¸­é€‰é‡‘é¢"].append(di["selected_amo"]cle
        ahref = base_url+str(di['to_page3'])
        data["to_page3"].append(ahref)
        #å¤„ç†ç¬¬ä¸‰é¡µ
        data["é¡¹ç›®è§„æ¨¡"].append("")
        data["æœåŠ¡å†…å®¹"].append("")
        data['æ‹ŸæœåŠ¡é‡‘é¢'].append(0) 

        # di:dict = popup_page3(browser.new_context(),ahref)
        # data["é¡¹ç›®è§„æ¨¡"].append(di["amo"])
        # data["æœåŠ¡å†…å®¹"].append(di["content"])
        # data['æ‹ŸæœåŠ¡é‡‘é¢'].append(di['servie_amo'])   
        df = pd.DataFrame(data)
        df.to_excel('è¾“å‡º.xlsx')  
    print("=====================================================") 
    browser.close()
    # time.sleep(2)

def open_page3(url:str):
    with sync_playwright() as playwright:
        browser = playwright.chromium.launch(headless=False)    
        page = browser.new_page()
        page.goto(url)


@flow(flow_run_name="å–æ•°æ®-on-{pagenu}")
def parse_html_flow(pagenu: int):
    logger = get_run_logger()
    logger.info('ç¬¬%dé¡µå¯åŠ¨'%(pagenu))
    htmlfile = r"file:///Users/ricochen/program/streamlit-example/html/adata%d.html"%pagenu
    with sync_playwright() as playwright:
        run(playwright,htmlfile)

if __name__ == "__main__":
    #creates a flow run called 'marvin-on-Thursday'
    file_path = r'./æ€»è¾“å‡º.xlsx'
    read_excel(file_path)
    #for i in range(0,424): #1417
        #my_flow(name="å–ä¸œèæ•°æ®", page=i)
        #parse_html_flow(i) #å–ç¬¬äºŒé¡µæ•°æ®
                            #å–ç¬¬ä¸‰é¡µæ•°æ®
        # time.sleep(3)    

    # df = pd.DataFrame(data)
    # df.to_excel('è¾“å‡º.xlsx')